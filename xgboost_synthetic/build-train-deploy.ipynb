{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and deploy on Kubeflow from Notebooks\n",
    "\n",
    "This notebook introduces you to using Kubeflow Fairing to train and deploy a model to Kubeflow on Google Kubernetes Engine (GKE), and Kubeflow Pipeline to build a simple pipeline and deploy on GKE. This notebook demonstrate how to:\n",
    " \n",
    "* Train an XGBoost model in a local notebook,\n",
    "* Use Kubeflow Fairing to train an XGBoost model remotely on Kubeflow,\n",
    "  * For simplicity code-generated synthetic data is used.\n",
    "  * The append builder is used to rapidly build a docker image.\n",
    "* Use Kubeflow Fairing to deploy a trained model to Kubeflow, and Call the deployed endpoint for predictions.\n",
    "* Use a simple pipeline to train a model in GKE. \n",
    "\n",
    "To learn more about how to run this notebook locally, see the guide to [training and deploying on GCP from a local notebook][gcp-local-notebook].\n",
    "\n",
    "[gcp-local-notebook]: https://kubeflow.org/docs/fairing/gcp/tutorials/gcp-local-notebook/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up your notebook for training an XGBoost model\n",
    "\n",
    "Import the libraries required to train this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: retrying in /opt/conda/lib/python3.6/site-packages (1.3.3)\n",
      "Requirement already satisfied: six>=1.7.0 in /opt/conda/lib/python3.6/site-packages (from retrying) (1.12.0)\n",
      "\u001b[33mYou are using pip version 19.0.1, however version 19.2.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting https://github.com/kubeflow/fairing/archive/master.zip\n",
      "  Downloading https://github.com/kubeflow/fairing/archive/master.zip\n",
      "\u001b[K     | 2.6MB 80.3MB/ss\n",
      "Requirement already satisfied (use --upgrade to upgrade): fairing==0.5.3 from https://github.com/kubeflow/fairing/archive/master.zip in /opt/conda/lib/python3.6/site-packages\n",
      "Requirement already satisfied: docker>=3.4.1 in /opt/conda/lib/python3.6/site-packages (from fairing==0.5.3) (3.7.2)\n",
      "Requirement already satisfied: notebook>=5.6.0 in /opt/conda/lib/python3.6/site-packages (from fairing==0.5.3) (5.7.8)\n",
      "Requirement already satisfied: kubernetes>=9.0.0 in /opt/conda/lib/python3.6/site-packages (from fairing==0.5.3) (9.0.0)\n",
      "Requirement already satisfied: future>=0.17.1 in /opt/conda/lib/python3.6/site-packages (from fairing==0.5.3) (0.17.1)\n",
      "Requirement already satisfied: six>=1.11.0 in /opt/conda/lib/python3.6/site-packages (from fairing==0.5.3) (1.12.0)\n",
      "Requirement already satisfied: google-cloud-storage>=1.13.2 in /opt/conda/lib/python3.6/site-packages (from fairing==0.5.3) (1.14.0)\n",
      "Requirement already satisfied: requests>=2.21.0 in /opt/conda/lib/python3.6/site-packages (from fairing==0.5.3) (2.21.0)\n",
      "Requirement already satisfied: setuptools>=34.0.0 in /opt/conda/lib/python3.6/site-packages (from fairing==0.5.3) (40.9.0)\n",
      "Requirement already satisfied: google-auth>=1.6.2 in /opt/conda/lib/python3.6/site-packages (from fairing==0.5.3) (1.6.3)\n",
      "Requirement already satisfied: httplib2>=0.12.0 in /opt/conda/lib/python3.6/site-packages (from fairing==0.5.3) (0.12.1)\n",
      "Requirement already satisfied: oauth2client>=4.0.0 in /opt/conda/lib/python3.6/site-packages (from fairing==0.5.3) (4.1.3)\n",
      "Requirement already satisfied: tornado<6.0.0,>=5.1.1 in /opt/conda/lib/python3.6/site-packages (from fairing==0.5.3) (5.1.1)\n",
      "Requirement already satisfied: google-api-python-client>=1.7.8 in /opt/conda/lib/python3.6/site-packages (from fairing==0.5.3) (1.7.8)\n",
      "Requirement already satisfied: cloudpickle>=0.8 in /opt/conda/lib/python3.6/site-packages (from fairing==0.5.3) (0.8.1)\n",
      "Requirement already satisfied: numpy>=1.14 in /opt/conda/lib/python3.6/site-packages (from fairing==0.5.3) (1.16.2)\n",
      "Requirement already satisfied: urllib3==1.24.2 in /opt/conda/lib/python3.6/site-packages (from fairing==0.5.3) (1.24.2)\n",
      "Requirement already satisfied: boto3>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from fairing==0.5.3) (1.9.194)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.6/site-packages (from docker>=3.4.1->fairing==0.5.3) (0.4.0)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /opt/conda/lib/python3.6/site-packages (from docker>=3.4.1->fairing==0.5.3) (0.56.0)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.6/site-packages (from notebook>=5.6.0->fairing==0.5.3) (2.10)\n",
      "Requirement already satisfied: traitlets>=4.2.1 in /opt/conda/lib/python3.6/site-packages (from notebook>=5.6.0->fairing==0.5.3) (4.3.2)\n",
      "Requirement already satisfied: ipykernel in /opt/conda/lib/python3.6/site-packages (from notebook>=5.6.0->fairing==0.5.3) (5.1.0)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.6/site-packages (from notebook>=5.6.0->fairing==0.5.3) (0.2.0)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /opt/conda/lib/python3.6/site-packages (from notebook>=5.6.0->fairing==0.5.3) (0.8.2)\n",
      "Requirement already satisfied: jupyter-core>=4.4.0 in /opt/conda/lib/python3.6/site-packages (from notebook>=5.6.0->fairing==0.5.3) (4.4.0)\n",
      "Requirement already satisfied: pyzmq>=17 in /opt/conda/lib/python3.6/site-packages (from notebook>=5.6.0->fairing==0.5.3) (18.0.1)\n",
      "Requirement already satisfied: nbformat in /opt/conda/lib/python3.6/site-packages (from notebook>=5.6.0->fairing==0.5.3) (4.4.0)\n",
      "Requirement already satisfied: Send2Trash in /opt/conda/lib/python3.6/site-packages (from notebook>=5.6.0->fairing==0.5.3) (1.5.0)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.6/site-packages (from notebook>=5.6.0->fairing==0.5.3) (0.6.0)\n",
      "Requirement already satisfied: nbconvert in /opt/conda/lib/python3.6/site-packages (from notebook>=5.6.0->fairing==0.5.3) (5.4.1)\n",
      "Requirement already satisfied: jupyter-client>=5.2.0 in /opt/conda/lib/python3.6/site-packages (from notebook>=5.6.0->fairing==0.5.3) (5.2.4)\n",
      "Requirement already satisfied: requests-oauthlib in /opt/conda/lib/python3.6/site-packages (from kubernetes>=9.0.0->fairing==0.5.3) (1.2.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /opt/conda/lib/python3.6/site-packages (from kubernetes>=9.0.0->fairing==0.5.3) (2019.3.9)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /opt/conda/lib/python3.6/site-packages (from kubernetes>=9.0.0->fairing==0.5.3) (2.8.0)\n",
      "Requirement already satisfied: pyyaml>=3.12 in /opt/conda/lib/python3.6/site-packages (from kubernetes>=9.0.0->fairing==0.5.3) (5.1)\n",
      "Requirement already satisfied: google-resumable-media>=0.3.1 in /opt/conda/lib/python3.6/site-packages (from google-cloud-storage>=1.13.2->fairing==0.5.3) (0.3.2)\n",
      "Requirement already satisfied: google-cloud-core<0.30dev,>=0.29.0 in /opt/conda/lib/python3.6/site-packages (from google-cloud-storage>=1.13.2->fairing==0.5.3) (0.29.1)\n",
      "Requirement already satisfied: google-api-core<2.0.0dev,>=1.6.0 in /opt/conda/lib/python3.6/site-packages (from google-cloud-storage>=1.13.2->fairing==0.5.3) (1.9.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests>=2.21.0->fairing==0.5.3) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests>=2.21.0->fairing==0.5.3) (3.0.4)\n",
      "Requirement already satisfied: cachetools>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from google-auth>=1.6.2->fairing==0.5.3) (3.1.0)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth>=1.6.2->fairing==0.5.3) (4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.6/site-packages (from google-auth>=1.6.2->fairing==0.5.3) (0.2.4)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /opt/conda/lib/python3.6/site-packages (from oauth2client>=4.0.0->fairing==0.5.3) (0.4.5)\n",
      "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /opt/conda/lib/python3.6/site-packages (from google-api-python-client>=1.7.8->fairing==0.5.3) (3.0.0)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /opt/conda/lib/python3.6/site-packages (from google-api-python-client>=1.7.8->fairing==0.5.3) (0.0.3)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /opt/conda/lib/python3.6/site-packages (from boto3>=1.9.0->fairing==0.5.3) (0.2.1)\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.194 in /opt/conda/lib/python3.6/site-packages (from boto3>=1.9.0->fairing==0.5.3) (1.12.194)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.6/site-packages (from boto3>=1.9.0->fairing==0.5.3) (0.9.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.6/site-packages (from jinja2->notebook>=5.6.0->fairing==0.5.3) (1.1.1)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.6/site-packages (from traitlets>=4.2.1->notebook>=5.6.0->fairing==0.5.3) (4.4.0)\n",
      "Requirement already satisfied: ipython>=5.0.0 in /opt/conda/lib/python3.6/site-packages (from ipykernel->notebook>=5.6.0->fairing==0.5.3) (7.4.0)\n",
      "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /opt/conda/lib/python3.6/site-packages (from terminado>=0.8.1->notebook>=5.6.0->fairing==0.5.3) (0.6.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/lib/python3.6/site-packages (from nbformat->notebook>=5.6.0->fairing==0.5.3) (3.0.1)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.6/site-packages (from nbconvert->notebook>=5.6.0->fairing==0.5.3) (2.3.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.6/site-packages (from nbconvert->notebook>=5.6.0->fairing==0.5.3) (1.4.2)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /opt/conda/lib/python3.6/site-packages (from nbconvert->notebook>=5.6.0->fairing==0.5.3) (0.3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: testpath in /opt/conda/lib/python3.6/site-packages (from nbconvert->notebook>=5.6.0->fairing==0.5.3) (0.4.2)\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.6/site-packages (from nbconvert->notebook>=5.6.0->fairing==0.5.3) (3.1.0)\n",
      "Requirement already satisfied: mistune>=0.8.1 in /opt/conda/lib/python3.6/site-packages (from nbconvert->notebook>=5.6.0->fairing==0.5.3) (0.8.4)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.6/site-packages (from nbconvert->notebook>=5.6.0->fairing==0.5.3) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.6/site-packages (from requests-oauthlib->kubernetes>=9.0.0->fairing==0.5.3) (3.0.1)\n",
      "Requirement already satisfied: googleapis-common-protos!=1.5.4,<2.0dev,>=1.5.3 in /opt/conda/lib/python3.6/site-packages (from google-api-core<2.0.0dev,>=1.6.0->google-cloud-storage>=1.13.2->fairing==0.5.3) (1.5.9)\n",
      "Requirement already satisfied: protobuf>=3.4.0 in /opt/conda/lib/python3.6/site-packages (from google-api-core<2.0.0dev,>=1.6.0->google-cloud-storage>=1.13.2->fairing==0.5.3) (3.7.1)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.6/site-packages (from google-api-core<2.0.0dev,>=1.6.0->google-cloud-storage>=1.13.2->fairing==0.5.3) (2018.9)\n",
      "Requirement already satisfied: docutils<0.15,>=0.10 in /opt/conda/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.194->boto3>=1.9.0->fairing==0.5.3) (0.14)\n",
      "Requirement already satisfied: jedi>=0.10 in /opt/conda/lib/python3.6/site-packages (from ipython>=5.0.0->ipykernel->notebook>=5.6.0->fairing==0.5.3) (0.13.3)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.6/site-packages (from ipython>=5.0.0->ipykernel->notebook>=5.6.0->fairing==0.5.3) (0.7.5)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.6/site-packages (from ipython>=5.0.0->ipykernel->notebook>=5.6.0->fairing==0.5.3) (0.1.0)\n",
      "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from ipython>=5.0.0->ipykernel->notebook>=5.6.0->fairing==0.5.3) (2.0.9)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /opt/conda/lib/python3.6/site-packages (from ipython>=5.0.0->ipykernel->notebook>=5.6.0->fairing==0.5.3) (4.6.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.6/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->notebook>=5.6.0->fairing==0.5.3) (0.14.11)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.6/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->notebook>=5.6.0->fairing==0.5.3) (19.1.0)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.6/site-packages (from bleach->nbconvert->notebook>=5.6.0->fairing==0.5.3) (0.5.1)\n",
      "Requirement already satisfied: parso>=0.3.0 in /opt/conda/lib/python3.6/site-packages (from jedi>=0.10->ipython>=5.0.0->ipykernel->notebook>=5.6.0->fairing==0.5.3) (0.4.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.6/site-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=5.0.0->ipykernel->notebook>=5.6.0->fairing==0.5.3) (0.1.7)\n",
      "Building wheels for collected packages: fairing\n",
      "  Building wheel for fairing (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-ctd8rjlc/wheels/d7/62/60/cece640c93ab6418ee8a72f5cdca19b02eff4ce4515edbd99c\n",
      "Successfully built fairing\n",
      "\u001b[33mYou are using pip version 19.0.1, however version 19.2.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting kfmd\n",
      "  Downloading https://files.pythonhosted.org/packages/cf/72/048a49042dacd93925f6f4253cb765aeddef34da4cbec05066dc1ac555f5/kfmd-0.1.8.tar.gz\n",
      "Building wheels for collected packages: kfmd\n",
      "  Building wheel for kfmd (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/3d/ef/17/5f5099e588c582d66506547e0bd28bd7071959137a88b110ca\n",
      "Successfully built kfmd\n",
      "Installing collected packages: kfmd\n",
      "Successfully installed kfmd-0.1.8\n",
      "\u001b[33mYou are using pip version 19.0.1, however version 19.2.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install retrying\n",
    "!pip3 install https://github.com/kubeflow/fairing/archive/master.zip\n",
    "!pip3 install kfmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import util\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "############# delete ########\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/home/jovyan/key.json\"\n",
    "util.notebook_setup()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fairing:include-cell\n",
    "import fire\n",
    "import joblib\n",
    "import logging\n",
    "import kfmd\n",
    "import nbconvert\n",
    "import os\n",
    "import pathlib\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import pprint\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from xgboost import XGBRegressor\n",
    "from importlib import reload\n",
    "from sklearn.datasets import make_regression\n",
    "from kfmd import metadata\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports not to be included in the built docker image\n",
    "import kfp\n",
    "import kfp.components as comp\n",
    "import kfp.gcp as gcp\n",
    "import kfp.dsl as dsl\n",
    "import kfp.compiler as compiler\n",
    "from kubernetes import client as k8s_client\n",
    "import fairing   \n",
    "from fairing.builders import append\n",
    "from fairing.deployers import job\n",
    "from fairing.preprocessors.converted_notebook import ConvertNotebookPreprocessorWithFire\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fairing:include-cell\n",
    "def read_synthetic_input(test_size=0.25):\n",
    "    \"\"\"generate synthetic data and split it into train and test.\"\"\"\n",
    "    # generate regression dataset\n",
    "    X, y = make_regression(n_samples=200, n_features=5, noise=0.1)\n",
    "    train_X, test_X, train_y, test_y = train_test_split(X,\n",
    "                                                      y,\n",
    "                                                      test_size=test_size,\n",
    "                                                      shuffle=False)\n",
    "\n",
    "    imputer = SimpleImputer()\n",
    "    train_X = imputer.fit_transform(train_X)\n",
    "    test_X = imputer.transform(test_X)\n",
    "\n",
    "    return (train_X, train_y), (test_X, test_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fairing:include-cell\n",
    "def train_model(train_X,\n",
    "                train_y,\n",
    "                test_X,\n",
    "                test_y,\n",
    "                n_estimators,\n",
    "                learning_rate):\n",
    "    \"\"\"Train the model using XGBRegressor.\"\"\"\n",
    "    model = XGBRegressor(n_estimators=n_estimators, learning_rate=learning_rate)\n",
    "\n",
    "    model.fit(train_X,\n",
    "            train_y,\n",
    "            early_stopping_rounds=40,\n",
    "            eval_set=[(test_X, test_y)])\n",
    "\n",
    "    print(\"Best RMSE on eval: %.2f with %d rounds\",\n",
    "               model.best_score,\n",
    "               model.best_iteration+1)\n",
    "    return model\n",
    "\n",
    "def eval_model(model, test_X, test_y):\n",
    "    \"\"\"Evaluate the model performance.\"\"\"\n",
    "    predictions = model.predict(test_X)\n",
    "    mae=mean_absolute_error(predictions, test_y)\n",
    "    logging.info(\"mean_absolute_error=%.2f\", mae)\n",
    "    return mae\n",
    "\n",
    "def save_model(model, model_file):\n",
    "    \"\"\"Save XGBoost model for serving.\"\"\"\n",
    "    joblib.dump(model, model_file)\n",
    "    logging.info(\"Model export success: %s\", model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define various constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Train and Predict functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fairing:include-cell\n",
    "class ModelServe(object):\n",
    "    \n",
    "    def __init__(self, model_file=None):\n",
    "        self.n_estimators = 50\n",
    "        self.learning_rate = 0.1\n",
    "        if not model_file:\n",
    "            if \"MODEL_FILE\" in os.environ:\n",
    "                print(\"model_file not supplied; checking environment variable\")\n",
    "                model_file = os.getenv(\"MODEL_FILE\")\n",
    "            else:\n",
    "                print(\"model_file not supplied; using the default\")\n",
    "                model_file = \"mockup-model.dat\"\n",
    "        \n",
    "        self.model_file = model_file\n",
    "        print(\"model_file={0}\".format(self.model_file))\n",
    "        \n",
    "        self.model = None\n",
    "        self.exec = self.create_execution()\n",
    "\n",
    "    def train(self):\n",
    "        (train_X, train_y), (test_X, test_y) = read_synthetic_input()\n",
    "        self.exec.log_input(metadata.DataSet(\n",
    "            description=\"xgboost synthetic data\",\n",
    "            name=\"synthetic-data\",\n",
    "            owner=\"someone@kubeflow.org\",\n",
    "            uri=\"file://path/to/dataset\",\n",
    "            version=\"v1.0.0\"))\n",
    "        \n",
    "        model = train_model(train_X,\n",
    "                          train_y,\n",
    "                          test_X,\n",
    "                          test_y,\n",
    "                          self.n_estimators,\n",
    "                          self.learning_rate)\n",
    "\n",
    "        mae = eval_model(model, test_X, test_y)\n",
    "        self.exec.log_output(metadata.Metrics(\n",
    "            name=\"xgboost-synthetic-traing-eval\",\n",
    "            owner=\"someone@kubeflow.org\",\n",
    "            description=\"training evaluation for xgboost synthetic\",\n",
    "            uri=\"gcs://path/to/metrics\",\n",
    "            metrics_type=metadata.Metrics.VALIDATION,\n",
    "            values={\"mean_absolute_error\": mae}))\n",
    "        \n",
    "        save_model(model, self.model_file)\n",
    "        self.exec.log_output(metadata.Model(\n",
    "            name=\"housing-price-model\",\n",
    "            description=\"housing price prediction model using synthetic data\",\n",
    "            owner=\"someone@kubeflow.org\",\n",
    "            uri=self.model_file,\n",
    "            model_type=\"linear_regression\",\n",
    "            training_framework={\n",
    "                \"name\": \"xgboost\",\n",
    "                \"version\": \"0.9.0\"\n",
    "            },\n",
    "            hyperparameters={\n",
    "                \"learning_rate\": self.learning_rate,\n",
    "                \"n_estimators\": self.n_estimators\n",
    "            },\n",
    "            version=datetime.utcnow().isoformat(\"T\")))\n",
    "        \n",
    "    def predict(self, X, feature_names):\n",
    "        \"\"\"Predict using the model for given ndarray.\"\"\"\n",
    "        if not self.model:\n",
    "            self.model = joblib.load(self.model_file)\n",
    "        # Do any preprocessing\n",
    "        prediction = self.model.predict(data=X)\n",
    "        # Do any postprocessing\n",
    "        return [[prediction.item(0), prediction.item(0)]]\n",
    "    \n",
    "    def create_execution(self):\n",
    "        workspace = metadata.Workspace(\n",
    "        # Connect to metadata-service in namesapce kubeflow in k8s cluster.\n",
    "        backend_url_prefix=\"metadata-service.kubeflow:8080\",\n",
    "        name=\"xgboost-synthetic\",\n",
    "        description=\"workspace for xgboost-synthetic artifacts and executions\")\n",
    "        \n",
    "        r = metadata.Run(\n",
    "            workspace=workspace,\n",
    "            name=\"xgboost-synthetic-faring-run\" + datetime.utcnow().isoformat(\"T\"),\n",
    "            description=\"a notebook run\")\n",
    "\n",
    "        return metadata.Execution(\n",
    "            name = \"execution\" + datetime.utcnow().isoformat(\"T\"),\n",
    "            workspace=workspace,\n",
    "            run=r,\n",
    "            description=\"execution for training xgboost-synthetic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train your Model Locally\n",
    "\n",
    "* Train your model locally inside your notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_file=mockup-model.dat\n",
      "[0]\tvalidation_0-rmse:140.364\n",
      "Will train until validation_0-rmse hasn't improved in 40 rounds.\n",
      "[1]\tvalidation_0-rmse:134.368\n",
      "[2]\tvalidation_0-rmse:128.262\n",
      "[3]\tvalidation_0-rmse:122.131\n",
      "[4]\tvalidation_0-rmse:117.647\n",
      "[5]\tvalidation_0-rmse:113.133\n",
      "[6]\tvalidation_0-rmse:108.111\n",
      "[7]\tvalidation_0-rmse:103.921\n",
      "[8]\tvalidation_0-rmse:101.611\n",
      "[9]\tvalidation_0-rmse:98.3824\n",
      "[10]\tvalidation_0-rmse:94.145\n",
      "[11]\tvalidation_0-rmse:91.121\n",
      "[12]\tvalidation_0-rmse:88.3225\n",
      "[13]\tvalidation_0-rmse:85.5555\n",
      "[14]\tvalidation_0-rmse:83.3553\n",
      "[15]\tvalidation_0-rmse:81.3385\n",
      "[16]\tvalidation_0-rmse:80.4257\n",
      "[17]\tvalidation_0-rmse:78.5906\n",
      "[18]\tvalidation_0-rmse:76.9606\n",
      "[19]\tvalidation_0-rmse:75.3192\n",
      "[20]\tvalidation_0-rmse:73.6229\n",
      "[21]\tvalidation_0-rmse:71.8799\n",
      "[22]\tvalidation_0-rmse:70.4872\n",
      "[23]\tvalidation_0-rmse:68.9296\n",
      "[24]\tvalidation_0-rmse:67.5273\n",
      "[25]\tvalidation_0-rmse:67.1219\n",
      "[26]\tvalidation_0-rmse:66.0533\n",
      "[27]\tvalidation_0-rmse:64.5362\n",
      "[28]\tvalidation_0-rmse:63.5446\n",
      "[29]\tvalidation_0-rmse:63.3588\n",
      "[30]\tvalidation_0-rmse:62.5707\n",
      "[31]\tvalidation_0-rmse:61.5752\n",
      "[32]\tvalidation_0-rmse:60.9208\n",
      "[33]\tvalidation_0-rmse:60.0488\n",
      "[34]\tvalidation_0-rmse:59.1477\n",
      "[35]\tvalidation_0-rmse:58.686\n",
      "[36]\tvalidation_0-rmse:58.5272\n",
      "[37]\tvalidation_0-rmse:57.9686\n",
      "[38]\tvalidation_0-rmse:57.3069\n",
      "[39]\tvalidation_0-rmse:56.6801\n",
      "[40]\tvalidation_0-rmse:56.1424\n",
      "[41]\tvalidation_0-rmse:55.7363\n",
      "[42]\tvalidation_0-rmse:55.2574\n",
      "[43]\tvalidation_0-rmse:54.9221\n",
      "[44]\tvalidation_0-rmse:54.7358\n",
      "[45]\tvalidation_0-rmse:54.3396\n",
      "[46]\tvalidation_0-rmse:53.9254\n",
      "[47]\tvalidation_0-rmse:53.3013\n",
      "[48]\tvalidation_0-rmse:52.9461\n",
      "[49]\tvalidation_0-rmse:52.4989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mean_absolute_error=36.96\n",
      "Model export success: mockup-model.dat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE on eval: %.2f with %d rounds 52.49889 50\n"
     ]
    }
   ],
   "source": [
    "ModelServe(model_file=\"mockup-model.dat\").train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict locally\n",
    "\n",
    "* Run prediction inside the notebook using the newly created notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_file not supplied; using the default\n",
      "model_file=mockup-model.dat\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[6.803134918212891, 6.803134918212891]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_X, train_y), (test_X, test_y) =read_synthetic_input()\n",
    "\n",
    "ModelServe().predict(test_X, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Fairing to Launch a K8s Job to train your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Kubeflow Fairing for training and predictions\n",
    "\n",
    "Import the `fairing` library and configure the environment that your training or prediction job will run in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zhenghui-kubeflow\n",
      "gcr.io/zhenghui-kubeflow/fairing-job\n"
     ]
    }
   ],
   "source": [
    "# Setting up google container repositories (GCR) for storing output containers\n",
    "# You can use any docker container registry istead of GCR\n",
    "GCP_PROJECT = fairing.cloud.gcp.guess_project_name()\n",
    "print(GCP_PROJECT)\n",
    "DOCKER_REGISTRY = 'gcr.io/{}/fairing-job'.format(GCP_PROJECT)\n",
    "print(DOCKER_REGISTRY)\n",
    "PY_VERSION = \".\".join([str(x) for x in sys.version_info[0:3]])\n",
    "BASE_IMAGE = 'python:{}'.format(PY_VERSION)\n",
    "# ucan use Dockerfile in this repo to build and use the base_image\n",
    "base_image = \"gcr.io/kubeflow-images-public/xgboost-fairing-example-base:v-20190612\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use fairing to build the docker image\n",
    "\n",
    "* This uses the append builder to rapidly build docker images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('build-train-deploy.py'), 'mockup-model.dat', 'xgboost_util.py']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fairing.builders import cluster\n",
    "preprocessor = ConvertNotebookPreprocessorWithFire(\"ModelServe\")\n",
    "\n",
    "if not preprocessor.input_files:\n",
    "    preprocessor.input_files = set()\n",
    "input_files=[\"xgboost_util.py\", \"mockup-model.dat\"]\n",
    "preprocessor.input_files =  set([os.path.normpath(f) for f in input_files])\n",
    "preprocessor.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building image using cluster builder.\n",
      "build-train-deploy.py already exists in Fairing context, skipping...\n",
      "build-train-deploy.py already exists in Fairing context, skipping...\n",
      "/tmp/fairing_dockerfile_uuj5upj9 already exists in Fairing context, skipping...\n",
      "/tmp/fairing_dockerfile_csmnoar3 already exists in Fairing context, skipping...\n",
      "Creating docker context: /tmp/fairing_context_0uul09r_\n",
      "build-train-deploy.py already exists in Fairing context, skipping...\n",
      "build-train-deploy.py already exists in Fairing context, skipping...\n",
      "build-train-deploy.py already exists in Fairing context, skipping...\n",
      "/tmp/fairing_dockerfile_uuj5upj9 already exists in Fairing context, skipping...\n",
      "/tmp/fairing_dockerfile_csmnoar3 already exists in Fairing context, skipping...\n",
      "/tmp/fairing_dockerfile_ohhy43dg already exists in Fairing context, skipping...\n",
      "Not able to find gcp credentials secret: user-gcp-sa\n",
      "Waiting for fairing-builder-6xb6v to start...\n",
      "Waiting for fairing-builder-6xb6v to start...\n",
      "Waiting for fairing-builder-6xb6v to start...\n",
      "Waiting for fairing-builder-6xb6v to start...\n",
      "Pod started running True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mINFO\u001b[0m[0006] Downloading base image gcr.io/kubeflow-images-public/xgboost-fairing-example-base:v-20190612\n",
      "\u001b[36mINFO\u001b[0m[0006] Downloading base image gcr.io/kubeflow-images-public/xgboost-fairing-example-base:v-20190612\n",
      "\u001b[33mWARN\u001b[0m[0006] Error while retrieving image from cache: getting image from path: open /cache/sha256:f90e54e312c4cfba28bec6993add2a85b4e127b52149ec0aaf41e5f8889a4086: no such file or directory\n",
      "\u001b[36mINFO\u001b[0m[0006] Checking for cached layer gcr.io/zhenghui-kubeflow/fairing-job/fairing-job/cache:e46cfa04f5f0d0445ce3ce8b91886d94e96f2875510a69aa9afaeb0ba9e62fc4...\n",
      "\u001b[36mINFO\u001b[0m[0006] No cached layer found for cmd RUN if [ -e requirements.txt ];then pip install --no-cache -r requirements.txt; fi\n",
      "\u001b[36mINFO\u001b[0m[0006] Unpacking rootfs as cmd RUN if [ -e requirements.txt ];then pip install --no-cache -r requirements.txt; fi requires it.\n",
      "\u001b[36mINFO\u001b[0m[0116] Taking snapshot of full filesystem...\n",
      "\u001b[36mINFO\u001b[0m[0131] Skipping paths under /dev, as it is a whitelisted directory\n",
      "\u001b[36mINFO\u001b[0m[0131] Skipping paths under /kaniko, as it is a whitelisted directory\n",
      "\u001b[36mINFO\u001b[0m[0133] Skipping paths under /proc, as it is a whitelisted directory\n",
      "\u001b[36mINFO\u001b[0m[0133] Skipping paths under /sys, as it is a whitelisted directory\n",
      "\u001b[36mINFO\u001b[0m[0133] Skipping paths under /var/run, as it is a whitelisted directory\n",
      "\u001b[36mINFO\u001b[0m[0270] WORKDIR /app/\n",
      "\u001b[36mINFO\u001b[0m[0270] cmd: workdir\n",
      "\u001b[36mINFO\u001b[0m[0270] Changed working directory to /app/\n",
      "\u001b[36mINFO\u001b[0m[0270] Creating directory /app/\n",
      "\u001b[36mINFO\u001b[0m[0270] Taking snapshot of files...\n",
      "\u001b[36mINFO\u001b[0m[0270] ENV FAIRING_RUNTIME 1\n",
      "\u001b[36mINFO\u001b[0m[0270] No files changed in this command, skipping snapshotting.\n",
      "\u001b[36mINFO\u001b[0m[0270] RUN if [ -e requirements.txt ];then pip install --no-cache -r requirements.txt; fi\n",
      "\u001b[36mINFO\u001b[0m[0270] cmd: /bin/bash\n",
      "\u001b[36mINFO\u001b[0m[0270] args: [-c if [ -e requirements.txt ];then pip install --no-cache -r requirements.txt; fi]\n",
      "\u001b[36mINFO\u001b[0m[0270] Taking snapshot of full filesystem...\n",
      "\u001b[36mINFO\u001b[0m[0280] Skipping paths under /dev, as it is a whitelisted directory\n",
      "\u001b[36mINFO\u001b[0m[0280] Skipping paths under /kaniko, as it is a whitelisted directory\n",
      "\u001b[36mINFO\u001b[0m[0281] Skipping paths under /proc, as it is a whitelisted directory\n",
      "\u001b[36mINFO\u001b[0m[0281] Skipping paths under /sys, as it is a whitelisted directory\n",
      "\u001b[36mINFO\u001b[0m[0282] Skipping paths under /var/run, as it is a whitelisted directory\n",
      "\u001b[36mINFO\u001b[0m[0314] No files were changed, appending empty layer to config. No layer added to image.\n",
      "\u001b[36mINFO\u001b[0m[0314] Using files from context: [/kaniko/buildcontext/app]\n",
      "\u001b[36mINFO\u001b[0m[0314] COPY /app/ /app/\n",
      "\u001b[36mINFO\u001b[0m[0314] Pushing layer gcr.io/zhenghui-kubeflow/fairing-job/fairing-job/cache:e46cfa04f5f0d0445ce3ce8b91886d94e96f2875510a69aa9afaeb0ba9e62fc4 to cache now\n",
      "\u001b[36mINFO\u001b[0m[0314] Taking snapshot of files...\n",
      "\u001b[33mWARN\u001b[0m[0316] error uploading layer to cache: failed to push to destination gcr.io/zhenghui-kubeflow/fairing-job/fairing-job/cache:e46cfa04f5f0d0445ce3ce8b91886d94e96f2875510a69aa9afaeb0ba9e62fc4: DENIED: \"Access denied.\"\n",
      "error pushing image: failed to push to destination gcr.io/zhenghui-kubeflow/fairing-job/fairing-job:AD2D2EDE: DENIED: \"Access denied.\"\n"
     ]
    }
   ],
   "source": [
    "cluster_builder = cluster.cluster.ClusterBuilder(registry=DOCKER_REGISTRY,\n",
    "                                                 base_image=base_image,\n",
    "                                                 namespace='zhenghui-at-google-com-e1e117',\n",
    "                                                 preprocessor=preprocessor,\n",
    "                                                 pod_spec_mutators=[fairing.cloud.gcp.add_gcp_credentials_if_exists],\n",
    "                                                 context_source=cluster.gcs_context.GCSContextSource())\n",
    "cluster_builder.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building image using Append builder...\n",
      "Creating docker context: /tmp/fairing_context_etb8hkx_\n",
      "build-train-deploy.py already exists in Fairing context, skipping...\n",
      "build-train-deploy.py already exists in Fairing context, skipping...\n",
      "build-train-deploy.py already exists in Fairing context, skipping...\n",
      "build-train-deploy.py already exists in Fairing context, skipping...\n",
      "build-train-deploy.py already exists in Fairing context, skipping...\n",
      "/tmp/fairing_dockerfile_mibzzsjo already exists in Fairing context, skipping...\n",
      "/tmp/fairing_dockerfile_4fakhp0m already exists in Fairing context, skipping...\n",
      "/tmp/fairing_dockerfile_l8_8yobc already exists in Fairing context, skipping...\n",
      "/tmp/fairing_dockerfile_6ppkd982 already exists in Fairing context, skipping...\n",
      "Loading Docker credentials for repository 'gcr.io/zhenghui-kubeflow/fairing-job/fairing-job:E58E6963'\n",
      "Invoking 'docker-credential-gcloud' to obtain Docker credentials.\n",
      "Successfully obtained Docker credentials.\n"
     ]
    },
    {
     "ename": "V2DiagnosticException",
     "evalue": "response: {'docker-distribution-api-version': 'registry/2.0', 'content-type': 'application/json', 'date': 'Thu, 25 Jul 2019 22:39:27 GMT', 'server': 'Docker Registry', 'cache-control': 'private', 'x-xss-protection': '0', 'x-frame-options': 'SAMEORIGIN', 'transfer-encoding': 'chunked', 'status': '404', 'content-length': '164', '-content-encoding': 'gzip'}\nFailed to fetch \"E58E6963\" from request \"/v2/zhenghui-kubeflow/fairing-job/fairing-job/manifests/E58E6963\".: None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mV2DiagnosticException\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-9df5aadd7aa0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m builder = append.append.AppendBuilder(registry=DOCKER_REGISTRY,\n\u001b[1;32m      2\u001b[0m                                       base_image=cluster_builder.image_tag, preprocessor=preprocessor)\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/fairing/builders/append/append.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Building image using Append builder...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mnew_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Image successfully built in {}s.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/fairing/builders/append/append.py\u001b[0m in \u001b[0;36m_build\u001b[0;34m(self, transport, src)\u001b[0m\n\u001b[1;32m     80\u001b[0m                     overrides=metadata.Overrides(cmd=self.preprocessor.get_command(),\n\u001b[1;32m     81\u001b[0m                                                  \u001b[0muser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'0'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m                                                  env={\"FAIRING_RUNTIME\": \"1\"}))\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnew_img\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/containerregistry/client/v2_2/append_.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, base, tar_gz, diff_id, overrides)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \"\"\"\n\u001b[1;32m     56\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_base\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mmanifest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanifest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0mconfig_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/containerregistry/client/v2_2/docker_image_.py\u001b[0m in \u001b[0;36mmanifest\u001b[0;34m(self, validate)\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocker_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m       \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'manifests/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accepted_mimes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m       \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocker_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDigest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/containerregistry/client/v2_2/docker_image_.py\u001b[0m in \u001b[0;36m_content\u001b[0;34m(self, suffix, accepted_mimes, cache)\u001b[0m\n\u001b[1;32m    265\u001b[0m             suffix=suffix),\n\u001b[1;32m    266\u001b[0m         \u001b[0maccepted_codes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoves\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOK\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         accepted_mimes=accepted_mimes)\n\u001b[0m\u001b[1;32m    268\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_response\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msuffix\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/containerregistry/client/v2_2/docker_http_.py\u001b[0m in \u001b[0;36mRequest\u001b[0;34m(self, url, accepted_codes, method, body, content_type, accepted_mimes)\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maccepted_codes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m       \u001b[0;31m# Use the content returned by GCR as the error message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mV2DiagnosticException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mV2DiagnosticException\u001b[0m: response: {'docker-distribution-api-version': 'registry/2.0', 'content-type': 'application/json', 'date': 'Thu, 25 Jul 2019 22:39:27 GMT', 'server': 'Docker Registry', 'cache-control': 'private', 'x-xss-protection': '0', 'x-frame-options': 'SAMEORIGIN', 'transfer-encoding': 'chunked', 'status': '404', 'content-length': '164', '-content-encoding': 'gzip'}\nFailed to fetch \"E58E6963\" from request \"/v2/zhenghui-kubeflow/fairing-job/fairing-job/manifests/E58E6963\".: None"
     ]
    }
   ],
   "source": [
    "builder = append.append.AppendBuilder(registry=DOCKER_REGISTRY,\n",
    "                                      base_image=cluster_builder.image_tag, preprocessor=preprocessor)\n",
    "builder.build()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch the K8s Job\n",
    "\n",
    "* Use pod mutators to attach a PVC and credentials to the pod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'builder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-a9c69f8fd779>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpod_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_pod_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mNAMESPACE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"user1\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m train_deployer = job.job.Job(namespace=NAMESPACE, \n\u001b[1;32m      4\u001b[0m                              \u001b[0mcleanup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                              pod_spec_mutators=[\n",
      "\u001b[0;31mNameError\u001b[0m: name 'builder' is not defined"
     ]
    }
   ],
   "source": [
    "pod_spec = builder.generate_pod_spec()\n",
    "NAMESPACE = \"user1\"\n",
    "train_deployer = job.job.Job(namespace=NAMESPACE, \n",
    "                             cleanup=False,\n",
    "                             pod_spec_mutators=[\n",
    "                             fairing.cloud.gcp.add_gcp_credentials_if_exists])\n",
    "\n",
    "# Add command line arguments\n",
    "pod_spec.containers[0].command.extend([\"train\"])\n",
    "result = train_deployer.deploy(pod_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl get jobs -l fairing-id={train_deployer.job_id} -o yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the trained model to Kubeflow for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Cluster endpoint: http://fairing-service-jjgxd.user1.svc.cluster.local\n"
     ]
    }
   ],
   "source": [
    "from fairing.deployers import serving\n",
    "pod_spec = builder.generate_pod_spec()\n",
    "\n",
    "module_name = os.path.splitext(preprocessor.executable.name)[0]\n",
    "deployer = serving.serving.Serving(module_name + \".ModelServe\",\n",
    "                                   service_type=\"ClusterIP\",\n",
    "                                   labels={\"app\": \"mockup\"})\n",
    "    \n",
    "url = deployer.deploy(pod_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: extensions/v1beta1\r\n",
      "kind: Deployment\r\n",
      "metadata:\r\n",
      "  annotations:\r\n",
      "    deployment.kubernetes.io/revision: \"1\"\r\n",
      "  creationTimestamp: \"2019-06-12T20:22:27Z\"\r\n",
      "  generateName: fairing-deployer-\r\n",
      "  generation: 1\r\n",
      "  labels:\r\n",
      "    app: mockup\r\n",
      "    fairing-deployer: serving\r\n",
      "    fairing-id: cbc0e610-8d4f-11e9-9207-96ec34699c76\r\n",
      "  name: fairing-deployer-cltbb\r\n",
      "  namespace: user1\r\n",
      "  resourceVersion: \"7556174\"\r\n",
      "  selfLink: /apis/extensions/v1beta1/namespaces/user1/deployments/fairing-deployer-cltbb\r\n",
      "  uid: cbc54e8f-8d4f-11e9-b008-42010a8e01a5\r\n",
      "spec:\r\n",
      "  progressDeadlineSeconds: 600\r\n",
      "  replicas: 1\r\n",
      "  revisionHistoryLimit: 10\r\n",
      "  selector:\r\n",
      "    matchLabels:\r\n",
      "      app: mockup\r\n",
      "      fairing-deployer: serving\r\n",
      "      fairing-id: cbc0e610-8d4f-11e9-9207-96ec34699c76\r\n",
      "  strategy:\r\n",
      "    rollingUpdate:\r\n",
      "      maxSurge: 25%\r\n",
      "      maxUnavailable: 25%\r\n",
      "    type: RollingUpdate\r\n",
      "  template:\r\n",
      "    metadata:\r\n",
      "      creationTimestamp: null\r\n",
      "      labels:\r\n",
      "        app: mockup\r\n",
      "        fairing-deployer: serving\r\n",
      "        fairing-id: cbc0e610-8d4f-11e9-9207-96ec34699c76\r\n",
      "      name: fairing-deployer\r\n",
      "    spec:\r\n",
      "      containers:\r\n",
      "      - command:\r\n",
      "        - seldon-core-microservice\r\n",
      "        - mockup-data-xgboost-build-train-deploy.ModelServe\r\n",
      "        - REST\r\n",
      "        - --service-type=MODEL\r\n",
      "        - --persistence=0\r\n",
      "        env:\r\n",
      "        - name: FAIRING_RUNTIME\r\n",
      "          value: \"1\"\r\n",
      "        image: gcr.io/zahrakubeflowcodelab/fairing-job/fairing-job:6F63F28C\r\n",
      "        imagePullPolicy: IfNotPresent\r\n",
      "        name: model\r\n",
      "        resources: {}\r\n",
      "        securityContext:\r\n",
      "          runAsUser: 0\r\n",
      "        terminationMessagePath: /dev/termination-log\r\n",
      "        terminationMessagePolicy: File\r\n",
      "        workingDir: /app/\r\n",
      "      dnsPolicy: ClusterFirst\r\n",
      "      restartPolicy: Always\r\n",
      "      schedulerName: default-scheduler\r\n",
      "      securityContext: {}\r\n",
      "      terminationGracePeriodSeconds: 30\r\n",
      "status:\r\n",
      "  availableReplicas: 1\r\n",
      "  conditions:\r\n",
      "  - lastTransitionTime: \"2019-06-12T20:22:29Z\"\r\n",
      "    lastUpdateTime: \"2019-06-12T20:22:29Z\"\r\n",
      "    message: Deployment has minimum availability.\r\n",
      "    reason: MinimumReplicasAvailable\r\n",
      "    status: \"True\"\r\n",
      "    type: Available\r\n",
      "  - lastTransitionTime: \"2019-06-12T20:22:27Z\"\r\n",
      "    lastUpdateTime: \"2019-06-12T20:22:29Z\"\r\n",
      "    message: ReplicaSet \"fairing-deployer-cltbb-864d4d6f8f\" has successfully progressed.\r\n",
      "    reason: NewReplicaSetAvailable\r\n",
      "    status: \"True\"\r\n",
      "    type: Progressing\r\n",
      "  observedGeneration: 1\r\n",
      "  readyReplicas: 1\r\n",
      "  replicas: 1\r\n",
      "  updatedReplicas: 1\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get deploy -o yaml {deployer.deployment.metadata.name}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call the prediction endpoint\n",
    "\n",
    "Create a test dataset, then call the endpoint on Kubeflow for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_X, train_y), (test_X, test_y) =read_synthetic_input()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(b'<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 3.2 Final//EN\">\\n<title>500 Inter'\n",
      " b'nal Server Error</title>\\n<h1>Internal Server Error</h1>\\n<p>The server en'\n",
      " b'countered an internal error and was unable to complete your request. Either '\n",
      " b'the server is overloaded or there is an error in the application.</p>\\n')\n"
     ]
    }
   ],
   "source": [
    "full_url = url + \":5000/predict\"\n",
    "result = util.predict_nparray(full_url, test_X)\n",
    "pprint.pprint(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up the prediction endpoint\n",
    "\n",
    "Delete the prediction endpoint created by this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !kubectl delete service -l app=ames\n",
    "# !kubectl delete deploy -l app=ames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a simple 1 step pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = 'MockupModel'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the pipeline\n",
    "Pipeline function has to be decorated with the `@dsl.pipeline` decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "   name='Training pipeline',\n",
    "   description='A pipeline that trains an xgboost model for the Ames dataset.'\n",
    ")\n",
    "def train_pipeline(\n",
    "   ):      \n",
    "    command=[\"python\", preprocessor.executable.name, \"train\"]\n",
    "    train_op = dsl.ContainerOp(\n",
    "            name=\"train\", \n",
    "            image=builder.image_tag,        \n",
    "            command=command,\n",
    "            ).apply(\n",
    "                gcp.use_gcp_secret('user-gcp-sa'),\n",
    "            )\n",
    "    train_op.container.working_dir = \"/app\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_func = train_pipeline\n",
    "pipeline_filename = pipeline_func.__name__ + '.pipeline.zip'\n",
    "compiler.Compiler().compile(pipeline_func, pipeline_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit the pipeline for execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Creating experiment MockupModel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Experiment link <a href=\"/pipeline/#/experiments/details/a446547d-14f7-4dae-935b-a3a66fceea44\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"/pipeline/#/runs/details/d0778d1d-8d50-11e9-b008-42010a8e01a5\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Specify pipeline argument values\n",
    "arguments = {}\n",
    "\n",
    "# Get or create an experiment and submit a pipeline run\n",
    "client = kfp.Client()\n",
    "experiment = client.create_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "#Submit a pipeline run\n",
    "run_name = pipeline_func.__name__ + ' run'\n",
    "run_result = client.run_pipeline(experiment.id, run_name, pipeline_filename, arguments)\n",
    "\n",
    "#vvvvvvvvv This link leads to the run information page. (Note: There is a bug in JupyterLab that modifies the URL and makes the link stop working)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
